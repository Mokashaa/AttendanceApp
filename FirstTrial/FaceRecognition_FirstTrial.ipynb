{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceRecognition_FirstTrial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypqeLBqZedgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84de70a1-07ad-4455-d12b-9297d76bc902"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.engine.topology import Layer\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from fr_utils import *\n",
        "from inception_blocks_v2 import *\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7542266f341f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfr_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0minception_blocks_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fr_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmQfORftfwuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21357af5-6f9c-4c84-e1b6-a5f4ef4150d0"
      },
      "source": [
        "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-21b4ceca697f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFRmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaceRecoModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'faceRecoModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTOcWI5zfzja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60655de-d7bf-4bdf-880d-f6141cedca01"
      },
      "source": [
        "print(\"Total Params:\", FRmodel.count_params())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d213b1bfc973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Params:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'FRmodel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p93AhhNmf1-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
        "        \n",
        "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
        "    \n",
        "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)), axis = -1)\n",
        "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)), axis = -1)\n",
        "    basic_loss = pos_dist - neg_dist + alpha\n",
        "    loss = tf.reduce_sum(tf.maximum(basic_loss,0.0))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTaqr-RVf4xY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edccecb1-47e6-40f8-c0f8-c2d6bb9ac9fe"
      },
      "source": [
        "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
        "load_weights_from_FaceNet(FRmodel)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e3a02b5b8708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFRmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriplet_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mload_weights_from_FaceNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFRmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'FRmodel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTxEFedZf665",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "def add_to_database (img1,img2,img3,id):\n",
        "    frame = plt.imread(img1, 1)\n",
        "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
        "    database = pd.read_csv('database.csv',index_col=0)\n",
        "    for (x, y, w, h) in faces:\n",
        "        roi = frame[y:y + h, x:x + w]\n",
        "        cropped_img = cv2.resize(roi, (96, 96))\n",
        "        plt.imshow(cropped_img, cmap = 'Greys_r')\n",
        "        encoding1 = img_to_encoding(cropped_img, FRmodel)\n",
        "        \n",
        "    frame = plt.imread(img2, 1)\n",
        "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
        "    database = pd.read_csv('database.csv',index_col=0)\n",
        "    for (x, y, w, h) in faces:\n",
        "        roi = frame[y:y + h, x:x + w]\n",
        "        cropped_img = cv2.resize(roi, (96, 96))\n",
        "        plt.imshow(cropped_img, cmap = 'Greys_r')\n",
        "        encoding2 = img_to_encoding(cropped_img, FRmodel)\n",
        "\n",
        "    frame = plt.imread(img3, 1)\n",
        "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
        "    database = pd.read_csv('database.csv',index_col=0)\n",
        "    for (x, y, w, h) in faces:\n",
        "        roi = frame[y:y + h, x:x + w]\n",
        "        cropped_img = cv2.resize(roi, (96, 96))\n",
        "        plt.imshow(cropped_img, cmap = 'Greys_r')\n",
        "        encoding3 = img_to_encoding(cropped_img, FRmodel)\n",
        "        \n",
        "    encoding=np.concatenate((encoding1[0],encoding2[0],encoding3[0]) , axis=0)\n",
        "    print(len(encoding))\n",
        "    database.loc[id]=encoding\n",
        "    database.to_csv('database.csv')\n",
        "    print(id)\n",
        "            \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B24l52rHf-qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "add_to_database(\"images/omar.jpg\",\"images/try.jpg\",\"images/try5.jpg\",1500121) #elite\n",
        "add_to_database(\"images/g1.jpg\",\"images/g2.jpg\",\"images/g3.jpg\",1500122)    #ganz\n",
        "add_to_database(\"images/m1.jpg\",\"images/m2.jpg\",\"images/m3.jpg\",1500123)    #oksh\n",
        "add_to_database(\"images/h1.jpg\",\"images/h4.jpg\",\"images/h3.jpg\",1500125)    #hassan\n",
        "add_to_database(\"images/s4.jpg\",\"images/s5.jpg\",\"images/s8.jpg\",1500124)    #salma\n",
        "#add_to_database(\"images/m1.jpg\",\"images/m2.jpg\",\"images/m3.jpg\",1500126)    #hamed\n",
        "\n",
        "#add_to_database(\"images/denver.jpg\",1500122)\n",
        "#add_to_database(\"images/nairobi.jpg\",1500123)\n",
        "#add_to_database(\"images/tokyo.jpg\",1500124)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def who_is_it(image_path, model):\n",
        "    #Reading the image path that is passed to the function\n",
        "    frame = plt.imread(image_path, 1)\n",
        "    # Using the haarcascade to get the face coordinates in the image\n",
        "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
        "    #reading the database file which contains the encodings for each student image\n",
        "    database = pd.read_csv('database.csv',index_col=0)\n",
        "    identity = 0\n",
        "    for (x, y, w, h) in faces:\n",
        "        roi = frame[y:y + h, x:x + w]\n",
        "        cropped_img = cv2.resize(roi, (96, 96))\n",
        "        plt.imshow(cropped_img)\n",
        "        #After preprocessing the face of each person in the image\n",
        "        #We iterate into each face and get its encodings to use it in the comparison\n",
        "        encoding = img_to_encoding(cropped_img, FRmodel)\n",
        "        min_dist = 100\n",
        "        for id , db_enc in database.iterrows():\n",
        "            dist1 = np.linalg.norm(db_enc[:128] - encoding[0])\n",
        "            dist2 = np.linalg.norm(db_enc[128:256] - encoding[0])\n",
        "            dist3 = np.linalg.norm(db_enc[256:] - encoding[0])\n",
        "            #Compare the face with Every student 3 image encodings in the database\n",
        "            #Then take the minimum distance to identify the student\n",
        "            dist_avg = min(dist1,dist2,dist3)\n",
        "            print(dist1)\n",
        "            print(dist2)\n",
        "            print(dist3)\n",
        "            print(id)\n",
        "            if dist_avg < min_dist:\n",
        "                min_dist = dist_avg\n",
        "                identity = id\n",
        "\n",
        "        if min_dist > 0.8:\n",
        "            print(\"Not in the database.\" )\n",
        "            print(min_dist)\n",
        "        else:\n",
        "            #Here we state the name or code of the student that we find\n",
        "            print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
        "    "
      ]
    }
  ]
}